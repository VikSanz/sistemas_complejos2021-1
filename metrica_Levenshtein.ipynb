{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métrica de Levenshtein y Damerau-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoize(f):\n",
    "    cache = {}\n",
    "\n",
    "    def memoizedFunction(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = f(*args)\n",
    "        return cache[args]\n",
    "\n",
    "    memoizedFunction.cache = cache\n",
    "    return memoizedFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica de Levenshtein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize\n",
    "def dist1(word1, word2):\n",
    "    if not word1 or not word2:\n",
    "        return max(len(word1), len(word2))\n",
    "    elif word1[-1] == word2[-1]:\n",
    "        return dist(word1[:-1], word2[:-1])\n",
    "    else:\n",
    "        return min(dist(word1[:-1], word2) + 1,\n",
    "                        dist(word1, word2[:-1]) + 1,\n",
    "                        dist(word1[:-1], word2[:-1]) + 1)\n",
    "\n",
    "levenshteinDist = dist1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica de Damerau-Levenshtein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize\n",
    "def dist2(word1, word2):\n",
    "    if not word1 or not word2:\n",
    "        return max(len(word1), len(word2))\n",
    "    elif word1[-1] == word2[-1]:\n",
    "        return dist2(word1[:-1], word2[:-1])\n",
    "    else:\n",
    "        minDist = min(dist2(word1[:-1], word2) + 1,\n",
    "                                dist2(word1, word2[:-1]) + 1,\n",
    "                                dist2(word1[:-1], word2[:-1]) + 1)\n",
    "\n",
    "        # transposiciones\n",
    "        if len(word1) > 1 and len(word2) > 1:\n",
    "            if word1[-2] == word2[-1]:\n",
    "                transposedWord1 = word1[:-2] + word1[-1] + word1[-2]\n",
    "                minDist = min(minDist, dist2(transposedWord1[:-1], word2))\n",
    "\n",
    "            if word2[-2] == word1[-1]:\n",
    "                transposedWord2 = word2[:-2] + word2[-1] + word2[-2]\n",
    "                minDist = min(minDist, dist2(word1, transposedWord2[:-1]))\n",
    "\n",
    "        return minDist\n",
    "\n",
    "damerauLevenshteinDist = dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damerauLevenshteinDist('agua','atl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damerauLevenshteinDist('xolo','mozo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damerauLevenshteinDist('transposición','trasnposición')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDist('transposición','trasnposición')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuentos Nahuatl-Español "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCuentos():\n",
    "    cuentosEsp = []\n",
    "    cuentosNah = []\n",
    "    folder = \"corpusCuentos\"\n",
    "    files = [os.path.join(folder,val) for val in os.listdir(folder) if os.path.isfile(os.path.join(folder,val))]\n",
    "    for file in files:\n",
    "        f = open(file,\"r\",encoding=\"ISO-8859-1\")\n",
    "        l = f.read().split(\"\\n\")\n",
    "        if file.split(os.path.sep)[1][0:3]==\"esp\":\n",
    "            cuentosEsp.append([x for x in l if bool(x)])\n",
    "        elif file.split(os.path.sep)[1][0:3]==\"nah\":\n",
    "            cuentosNah.append([x for x in l if bool(x)])\n",
    "        f.close()\n",
    "    return cuentosEsp, cuentosNah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentences(cuentos):\n",
    "    f = []\n",
    "    for cuento in cuentos:\n",
    "        c = []\n",
    "        for par in cuento:\n",
    "            sentences = par.split(\".\")\n",
    "            sentences = [sub(r\"[^\\w\\s]\", \" \",sen) for sen in sentences if bool(sen)]\n",
    "            c.extend(sentences)\n",
    "        f.append(c)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuentosEsp, cuentosNah = getCuentos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuentosEsp, cuentosNah = getSentences(cuentosEsp), getSentences(cuentosNah)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las palabras en ambos idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_esp=[]\n",
    "oracionesEsp = [item.split(\" \") for l in cuentosEsp for item in l]\n",
    "p_esp = [item for lis in oracionesEsp for item in lis]\n",
    "p_esp=set(p_esp)\n",
    "palabras_esp=list(p_esp)\n",
    "palabras_esp.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_nah=[]\n",
    "oracionesNah = [item.split(\" \") for l in cuentosNah for item in l]\n",
    "p_nah = [item for lis in oracionesNah for item in lis]\n",
    "p_nah=set(p_nah)\n",
    "palabras_nah=list(p_nah)\n",
    "palabras_nah.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red de Damerau-Levenshtein "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos los vértices aislados i.e. damerauLevenshteinDist(i,j) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinNetwork(corpus1,corpus2):\n",
    "    levenG = nx.Graph()\n",
    "    nodes = corpus1 + corpus2\n",
    "    levenG.add_nodes_from(nodes)\n",
    "    for i in corpus1:\n",
    "        for j in corpus2:\n",
    "            if dist2(i,j) == 1:\n",
    "                levenG.add_edge(i,j)\n",
    "    return levenG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO incluimos los vértices aislados i.e. damerauLevenshteinDist(i,j) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinNetwork2(corpus1,corpus2):\n",
    "    levenG = nx.Graph()\n",
    "    nodes = corpus1 + corpus2\n",
    "    levenG.add_nodes_from(nodes)\n",
    "    for i in corpus1:\n",
    "        for j in corpus2:\n",
    "            if dist2(i,j) == 1:\n",
    "                levenG.add_edge(i,j)\n",
    "    list(nx.isolates(levenG))\n",
    "    levenG.remove_nodes_from(list(nx.isolates(levenG)))\n",
    "    return levenG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networkx.classes.graph.Graph"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grafica1 = levenshteinNetwork(palabras_esp,palabras_nah)\n",
    "type(grafica1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: Graph\\nNumber of nodes: 1518\\nNumber of edges: 227\\nAverage degree:   0.2991'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(grafica1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafica2 = levenshteinNetwork2(palabras_esp,palabras_nah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: Graph\\nNumber of nodes: 155\\nNumber of edges: 227\\nAverage degree:   2.9290'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(grafica2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(grafica2,'grafica2.gexf',version='1.2draft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo ejemplo damerauLevenshteinDist(i,j) > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinNetwork3(corpus1,corpus2):\n",
    "    levenG = nx.Graph()\n",
    "    nodes = corpus1 + corpus2\n",
    "    levenG.add_nodes_from(nodes)\n",
    "    for i in corpus1:\n",
    "        for j in corpus2:\n",
    "            if dist2(i,j) <= 2:\n",
    "                levenG.add_edge(i,j)\n",
    "    list(nx.isolates(levenG))\n",
    "    levenG.remove_nodes_from(list(nx.isolates(levenG)))\n",
    "    return levenG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafica3 = levenshteinNetwork3(palabras_esp,palabras_nah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: Graph\\nNumber of nodes: 466\\nNumber of edges: 2539\\nAverage degree:  10.8970'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(grafica3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(grafica3,'grafica3.gexf',version='1.2draft')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
